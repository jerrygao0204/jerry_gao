{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7d03cb-7479-454f-9371-1f81c889d7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尝试加载配置文件: /home/gaozheng/openai-quickstart/gaozheng/config.yaml\n",
      "成功加载配置文件\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "你:  你好啊\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 你好！有什么我可以帮助你的吗？\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "你:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "聊天结束。\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, List\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_openai import ChatOpenAI\n",
    "import yaml\n",
    "import logging\n",
    "from vector_store import VectorStoreManager\n",
    "from tools import Tools\n",
    "from pathlib import Path\n",
    "from logger import LoggerManager\n",
    "import tiktoken\n",
    "from IPython.display import Image, display\n",
    "from time import sleep\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# 加载配置文件\n",
    "def load_config():\n",
    "    try:\n",
    "        config_path = Path(\"config.yaml\")\n",
    "        print(f\"尝试加载配置文件: {config_path.absolute()}\")\n",
    "        \n",
    "        if not config_path.exists():\n",
    "            raise FileNotFoundError(f\"配置文件不存在: {config_path.absolute()}\")\n",
    "            \n",
    "        with open(config_path, 'r', encoding='utf-8') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "            \n",
    "        if config is None:\n",
    "            raise ValueError(\"配置文件为空或格式错误\")\n",
    "            \n",
    "        print(\"成功加载配置文件\")\n",
    "        return config\n",
    "    except Exception as e:\n",
    "        print(f\"加载配置文件时出错: {str(e)}\")\n",
    "        raise\n",
    "        \n",
    "# 控制token数量\n",
    "def trim_messages(messages: List[BaseMessage]) -> List[BaseMessage]:\n",
    "    try:\n",
    "        total_tokens = sum(len(tokenizer.encode(str(msg.content))) for msg in messages)\n",
    "        logger.info(f\"当前消息总token数: {total_tokens}\")\n",
    "        \n",
    "        max_tokens = config['messages']['max_context_length']\n",
    "        if total_tokens <= max_tokens:\n",
    "            return messages\n",
    "            \n",
    "        for msg in messages:\n",
    "            if len(tokenizer.encode(str(msg.content))) > max_tokens:\n",
    "                logger.warning(f\"发现过长消息: {len(tokenizer.encode(str(msg.content)))} tokens\")\n",
    "                \n",
    "        if config['messages']['trim_strategy'] == 'summary':\n",
    "            summary_prompt = f\"\"\"\n",
    "            请高度浓缩以下对话历史的关键信息，保留最重要的上下文。\n",
    "            总结应简洁明了，确保包含对话的核心主题和关键决策。\n",
    "            \n",
    "            对话历史：\n",
    "            {chr(10).join([f\"{msg.__class__.__name__}: {msg.content}\" for msg in messages])}\n",
    "            \"\"\"\n",
    "            \n",
    "            summary_response = summary_llm.invoke([\n",
    "                HumanMessage(content=summary_prompt)\n",
    "            ])\n",
    "            \n",
    "            summary_message = AIMessage(content=f\"对话历史总结: {summary_response.content}\")\n",
    "            recent_messages = messages[-config['messages']['keep_latest']:]\n",
    "            return [summary_message] + recent_messages\n",
    "        else:\n",
    "            return messages[-config['messages']['keep_latest']:]\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"消息裁剪失败: {str(e)}\", exc_info=True)\n",
    "        return messages[-config['messages']['keep_latest']:]\n",
    "\n",
    "# 从向量库查询数据\n",
    "def search_vector_db(query: str, k: int = 3) -> str:\n",
    "    \"\"\"搜索向量数据库中的相似内容\"\"\"\n",
    "    if not vector_store_manager:\n",
    "        return \"错误: 向量存储管理器未初始化\"\n",
    "    \n",
    "    try:\n",
    "        results = vector_store_manager.similarity_search(query, k=k)\n",
    "        if not results:\n",
    "            return \"未找到相关内容\"\n",
    "        \n",
    "        response_list = [f\"{i + 1}. {doc.page_content}{' 元数据: ' + str(doc.metadata) if doc.metadata else ''}\" for i, doc in enumerate(results)]\n",
    "        response = \"找到以下相关内容：\\n\" + \"\\n\".join(response_list)\n",
    "        return response\n",
    "    except AttributeError as e:\n",
    "        logger.error(f\"向量数据库搜索失败: {str(e)}\")\n",
    "        return f\"搜索失败: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"未知错误: {str(e)}\")\n",
    "        return f\"搜索失败: {str(e)}\"\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    chat_history: List[BaseMessage]  # 新增对话历史字段\n",
    "\n",
    "def chatbot(state: State):\n",
    "    try:\n",
    "        if not isinstance(state, dict) or \"messages\" not in state:\n",
    "            raise ValueError(\"无效的状态对象\")\n",
    "            \n",
    "        current_messages = state[\"messages\"]\n",
    "        chat_history = state.get(\"chat_history\", [])\n",
    "\n",
    "        if not current_messages:\n",
    "            return {\n",
    "                \"messages\": [AIMessage(content=\"没有收到消息\")],\n",
    "                \"chat_history\": chat_history\n",
    "            }\n",
    "\n",
    "        combined_messages = chat_history + current_messages\n",
    "        # 去除重复消息\n",
    "        unique_combined_messages = []\n",
    "        seen_messages = set()\n",
    "        for msg in combined_messages:\n",
    "            if msg.id not in seen_messages:\n",
    "                unique_combined_messages.append(msg)\n",
    "                seen_messages.add(msg.id)\n",
    "        \n",
    "        trimmed_messages = trim_messages(unique_combined_messages)\n",
    "\n",
    "        if not all(isinstance(msg, BaseMessage) for msg in trimmed_messages):\n",
    "            raise ValueError(\"所有的消息应该都是 BaseMessages 类型\")\n",
    "        \n",
    "        # 处理工具调用和响应的配对\n",
    "        final_messages = []\n",
    "        i = 0\n",
    "        while i < len(trimmed_messages):\n",
    "            message = trimmed_messages[i]\n",
    "            final_messages.append(message)\n",
    "            if (isinstance(message, AIMessage) and \n",
    "                hasattr(message, 'additional_kwargs') and \n",
    "                'tool_calls' in message.additional_kwargs):\n",
    "                \n",
    "                tool_calls = message.additional_kwargs['tool_calls']\n",
    "                next_index = i + 1\n",
    "                \n",
    "                # 检查每个工具调用是否有对应的响应\n",
    "                for tool_call in tool_calls:\n",
    "                    tool_call_id = tool_call['id']\n",
    "                    found_response = False\n",
    "                    \n",
    "                    # 查找对应的工具响应\n",
    "                    while next_index < len(trimmed_messages):\n",
    "                        next_msg = trimmed_messages[next_index]\n",
    "                        if (isinstance(next_msg, (AIMessage, ToolMessage)) and \n",
    "                            hasattr(next_msg, 'tool_call_id') and \n",
    "                            next_msg.tool_call_id == tool_call_id):\n",
    "                            found_response = True\n",
    "                            final_messages.append(next_msg)\n",
    "                            next_index += 1\n",
    "                            break\n",
    "                        next_index += 1\n",
    "                    \n",
    "                    if not found_response:\n",
    "                        # 如果没有找到响应，创建一个空响应\n",
    "                        empty_response = AIMessage(\n",
    "                            content=\"Tool response not found\",\n",
    "                            additional_kwargs={'tool_call_id': tool_call_id}\n",
    "                        )\n",
    "                        final_messages.append(empty_response)\n",
    "                \n",
    "                i = next_index\n",
    "                # print(\"Final Messages after processing tool calls:\", final_messages)\n",
    "            else:\n",
    "                i += 1\n",
    "        response = llm_with_tools.invoke(final_messages)\n",
    "        return {\n",
    "            \"messages\": [response],\n",
    "            \"chat_history\": final_messages + [response]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Chatbot 函数执行中出现错误: {str(e)}\", exc_info=True)\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"对话出现问题，请稍后再试。\")],\n",
    "            \"chat_history\": chat_history\n",
    "        }\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "# 设置日志记录的基本配置\n",
    "log_dir = Path(config['logging']['directory'])\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, config['logging']['level']),  # 日志记录的级别\n",
    "    format=config['logging']['format'],  # 日志记录的格式\n",
    "    filename=config['logging']['filename_pattern'],  # 日志记录的文件名模式\n",
    "    log_file_path = log_dir / config['logging']['filename_pattern']\n",
    ")\n",
    "\n",
    "# 获取一个名为当前模块名的日志记录器\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# 初始化日志记录管理器\n",
    "logger_manager = LoggerManager(config)\n",
    "logger = logger_manager.get_logger()  # 获取日志记录器\n",
    "\n",
    "# 获取模型编码的tokenizer\n",
    "tokenizer = tiktoken.get_encoding(config['model']['encoding_name'])\n",
    "\n",
    "# 初始化向量存储管理器\n",
    "vector_store_manager = VectorStoreManager(config)\n",
    "\n",
    "# 初始化工具实例\n",
    "tools_instance = Tools(config, vector_store_manager)\n",
    "\n",
    "# 创建OpenAI聊天模型实例\n",
    "llm = ChatOpenAI(\n",
    "    model=config['model']['name'],  # 模型名称\n",
    "    temperature=config['model']['temperature']  # 模型温度\n",
    ")\n",
    "\n",
    "# 将工具与语言模型绑定\n",
    "llm_with_tools = llm.bind_tools(tools_instance.tool_list)\n",
    "\n",
    "# 初始化内存保存器\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 创建状态图构建器\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 添加聊天机器人节点\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 添加工具节点\n",
    "tool_node = ToolNode(tools=tools_instance.tool_list)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "\n",
    "# 添加条件边用于节点之间的切换\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# 添加边从工具节点到聊天机器人节点\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "\n",
    "# 设置聊天机器人节点为入口点\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "\n",
    "# 编译状态图，使用内存检查点器\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# try:\n",
    "#     display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "# except Exception as e:\n",
    "#     logger.error(f\"图形可视化失败: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    current_chat_history = []  # 初始化对话历史\n",
    "    while True:\n",
    "        user_input = input(\"你: \")\n",
    "        if user_input.lower() == \"q\":\n",
    "            print(\"聊天结束。\")\n",
    "            break\n",
    "        \n",
    "        # inputs = {\"messages\": [HumanMessage(content=user_input)]}\n",
    "        inputs = {\n",
    "                \"messages\": [HumanMessage(content=user_input)],\n",
    "                \"chat_history\": current_chat_history  # 传入当前的对话历史\n",
    "                    }\n",
    "        config_dict = {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": config['graph'].get('thread_id', 'default_thread'),\n",
    "                \"checkpoint_ns\": config['graph'].get('checkpoint_ns', 'default_namespace'),\n",
    "                \"checkpoint_id\": config['graph'].get('checkpoint_id', 'default_checkpoint')\n",
    "            }\n",
    "        }\n",
    "        try:\n",
    "            for output in graph.stream(inputs, config=config_dict):\n",
    "                # 处理工具调用\n",
    "                messages = output.get('chatbot', {}).get('messages', [])\n",
    "                if messages and isinstance(messages[0], BaseMessage):\n",
    "                    if hasattr(messages[0], 'additional_kwargs') and 'tool_calls' in messages[0].additional_kwargs:\n",
    "                        tool_calls = messages[0].additional_kwargs['tool_calls']\n",
    "                        for tool_call in tool_calls:\n",
    "                            arguments = json.loads(tool_call['function']['arguments'])\n",
    "                            arguments.pop('self', None)\n",
    "                            tool_call['function']['arguments'] = json.dumps(arguments)\n",
    "                            tool_response = tools_instance.process_tool_call(tool_call)\n",
    "                            \n",
    "                            # 创建工具响应消息\n",
    "                            new_message = AIMessage(\n",
    "                                content=tool_response['output'],\n",
    "                                additional_kwargs={'tool_call_id': tool_response['tool_call_id']}\n",
    "                            )\n",
    "                            \n",
    "                            # 将工具响应添加到当前的对话历史\n",
    "                            if 'chat_history' in output.get('chatbot', {}):\n",
    "                                output['chatbot']['chat_history'].append(new_message)\n",
    "                                # print(output)\n",
    "                                # print(\"*\"*10)\n",
    "                            \n",
    "                    \n",
    "                    # 打印 AI 的响应消息\n",
    "                    for chat_history in messages:\n",
    "                        if chat_history.content is not None and chat_history.content != \"\":\n",
    "                            print(f\"AI: {chat_history.content}\")\n",
    "                        \n",
    "\n",
    "                    \n",
    "                # 更新对话历史\n",
    "                if 'chat_history' in output.get('chatbot', {}):\n",
    "                    current_chat_history = output['chatbot']['chat_history']\n",
    "                    # print(current_chat_history)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"聊天流处理错误: {str(e)}\", exc_info=True)\n",
    "            print(\"AI: 对话中出现问题，请稍后再试。\")\n",
    "\n",
    "        sleep(1)  # 模拟短暂的聊天停顿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c5d01-8901-4bac-ab8c-343143af0b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
